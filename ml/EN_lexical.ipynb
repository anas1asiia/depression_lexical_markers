{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b4dcfb",
   "metadata": {},
   "source": [
    "## Elastic Net\n",
    "\n",
    "EN_lexical.ipynb\n",
    "\n",
    "This script helps examine predictive power of lexical features (and TF-IDF) for \n",
    "predicting depression symptom severity (PHQ-8 scores). Developed as part of \n",
    "a study on multilingual lexical markers and depression severity.\n",
    "\n",
    "- Loads and preprocesses multilingual linguistic data (e.g., English, Dutch, Spanish)\n",
    "- Applies feature scaling and text vectorization (TF-IDF)\n",
    "- Constructs Elastic Net regression pipelines with and without feature selection\n",
    "- Implements nested GroupKFold cross-validation\n",
    "- Supports multiple feature combinations (lexical features only, features + TF-IDF, etc.)\n",
    "- Evaluates performance using RMSE and RÂ²\n",
    "- Supports grid search for hyperparameter tuning\n",
    "\n",
    "**Usage**:\n",
    "- Place your input CSV file in the desired directory.\n",
    "- Make sure the file includes a column named 'Text' containing the sentences.\n",
    "\n",
    "**Author**: Anastasiia Tokareva\n",
    "\n",
    "\n",
    "\n",
    "### Models tested:\n",
    "1. Baseline: full features, no TF-IDF\n",
    "2. Full features + TF-IDF\n",
    "3. SelectKBest() + PCA(0.95) + TF-IDF\n",
    "4. Stats-based features + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f056706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, cross_validate, GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD  # TSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33609a-b229-4918-87e6-c40598c0d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Clean your data\n",
    "data = pd.read_csv(\"C:/Users/your/file/name/here.csv\")  \n",
    "# remove missing values ('NA')\n",
    "data_cleaned = data.dropna(axis=0) \n",
    "\n",
    "# Below are the changes that were made to rename LIWC-generated column names, which differed \n",
    "# between the languages. Absolutist word frequency could only be extracted for English, so this\n",
    "# lexical feature was not included in the main ML models to enable comparison with Spanish\n",
    "# and Dutch data. Please uncomment the lines that you would like to run for your project.\n",
    "\n",
    "# a) English - remove the column with absolutist words \n",
    "# data_cleaned = data_cleaned.drop('allnone', axis=1)\n",
    "\n",
    "# b) Dutch - rename some columns to match English LIWC column names\n",
    "# data_cleaned = data_cleaned.rename(columns = {'posemo':'emo_pos', 'negemo':'emo_neg'})\n",
    "\n",
    "# c) Spanish - rename some columns to match English LIWC column names\n",
    "# data_cleaned = data_cleaned.rename(columns = {'EmoPos':'emo_pos', 'EmoNeg':'emo_neg', 'Yo':'i', 'Nosotro':'we', 'Pasado': 'focuspast'})\n",
    "\n",
    "\n",
    "## 2. Binarise COVID data\n",
    "data_cleaned['Recording_Date'] = pd.to_datetime(data_cleaned['Recording_Date'])\n",
    "\n",
    "# define COVID lockdown start and end dates (dates based on Leightley et al. (2021), https://pubmed.ncbi.nlm.nih.gov/34488697/)\n",
    "covid_start = pd.to_datetime('2020-03-23')\n",
    "covid_end = pd.to_datetime('2021-05-11')\n",
    "\n",
    "data_cleaned['COVID'] = ((data_cleaned['Recording_Date'] >= covid_start) & (data_cleaned['Recording_Date'] <= covid_end)).astype(int)\n",
    "data_cleaned.head(n=5)\n",
    "\n",
    "# COVID now added as the last column (0/1)\n",
    "data_cleaned.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44867438",
   "metadata": {},
   "source": [
    "#### 1. Baseline: lexical features only \n",
    "E.g., frequency of past-tense verbs, WPS, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "15a65a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (StandardScaler for numerical, and FunctionTransformer for raw features)\n",
    "preprocessor_1 = ColumnTransformer([\n",
    "    ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "                                       'WC', 'WPS', 'i', 'emo_neg', 'emo_pos', 'Brunet', 'we', \n",
    "                                       'focuspast', 'TTR']),                            # scale numerical features\n",
    "    ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # dummy variables unscaled\n",
    "])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_1 = Pipeline([\n",
    "    ('preprocessing', preprocessor_1),\n",
    "    ('regressor', ElasticNet())  # Elastic Net regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4be160",
   "metadata": {},
   "source": [
    "#### Grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd251155",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'regressor__alpha': [0.01, 0.1, 0.5, 1.0],   # regularization strength - had to remove 0, otherwise error with CV\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.9]       # balance between Lasso (l1) and Ridge (l2)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf61b3e",
   "metadata": {},
   "source": [
    "#### 2. Baseline + TF-IDF \n",
    "Lexical features + TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfaa0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (TF-IDF for text, StandardScaler for numerical)\n",
    "preprocessor_2 = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "    ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "                                       'WC', 'WPS', 'i', 'emo_neg', 'emo_pos', 'Brunet', 'we',\n",
    "                                       'focuspast', 'TTR']),                            # scale numerical features\n",
    "    ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # keeps dummy variables unscaled\n",
    "])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_2 = Pipeline([\n",
    "    ('preprocessing', preprocessor_2),\n",
    "    ('regressor', ElasticNet())  # Elastic Net regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a4477",
   "metadata": {},
   "source": [
    "#### 3. Automated + TF-IDF \n",
    "Selection of features based on their F-score using SelectKBest + dimensionality reduction using TSVD to preserve top 100 componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e43e8ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (StandardScaler for numerical, and FunctionTransformer for raw features)\n",
    "preprocessor_3 = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=500), 'Text'),           # TF-IDF (no scaling, as vectors are already scaled)\n",
    "    ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "                                       'WC', 'WPS', 'i', 'emo_neg', 'emo_pos', 'Brunet', 'we', \n",
    "                                       'focuspast', 'TTR']),                            # scale numerical features\n",
    "    ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # keeps dummy variables unscaled\n",
    "])\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_3 = Pipeline([\n",
    "    ('preprocessing', preprocessor_3),\n",
    "    ('feature_selection', SelectKBest(f_regression, k=100)),  \n",
    "    ('pca', TruncatedSVD(n_components=100)),  \n",
    "    ('regressor', ElasticNet()) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505c1f1",
   "metadata": {},
   "source": [
    "#### 4. Stats-based (no i, no past) + TF-IDF\n",
    "Removal of lexical features that were not strongly associated with PHQ-8 scores in Linear Mixed Modelling (LME), see lme in this repo for more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e053e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (StandardScaler for numerical, and FunctionTransformer for raw features)\n",
    "\n",
    "## In our project, different associations between lexical features and depression severity (PHQ-8 scores) were observed \n",
    "# for different languages. Please uncomment the following section to run the required model.\n",
    "\n",
    "# a) English --> only frequency of past-tense verbs and first-person singular pronouns NOT associated with\n",
    "# PHQ-8 scores --> remove this features\n",
    "\n",
    "# preprocessor_4 = ColumnTransformer([\n",
    "#     ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "#     ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "#                                        'WC', 'WPS', 'emo_neg', 'emo_pos', 'Brunet', 'we', 'allnone',\n",
    "#                                        'emo_anx', 'emo_anger', 'emo_sad','TTR']),       # scale numerical features\n",
    "#     ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # keeps dummy variables unscaled\n",
    "# ])\n",
    "\n",
    "# b) Dutch --> only WPS and emo_pos were strongly associated with PHQ-8 scores --> remove the rest\n",
    "\n",
    "# preprocessor_4 = ColumnTransformer([\n",
    "#     ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "#     ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "#                                     'WPS', 'emo_pos']),                                 # scale numerical features\n",
    "#     ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # keeps dummy variables unscaled\n",
    "# ])\n",
    "\n",
    "# c) Spanish - no lexical features were strongly associated with PHQ-8 scores --> remove all\n",
    "\n",
    "# preprocessor_4 = ColumnTransformer([\n",
    "#     ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "#     ('num_scaler', StandardScaler(), ['Age', 'Education_Years']),                         # scale numerical features\n",
    "#     ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])   # keeps dummy variables unscaled\n",
    "# ])\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_4 = Pipeline([\n",
    "    ('preprocessing', preprocessor_4),\n",
    "    ('regressor', ElasticNet()) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d5fe8",
   "metadata": {},
   "source": [
    "### Custom RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4698287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RMSE scorer\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Define the scorers dictionary\n",
    "scorers = {\n",
    "    'rmse': make_scorer(rmse),\n",
    "    'r2': make_scorer(r2_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d42bd9",
   "metadata": {},
   "source": [
    "### Set up nested CFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0072cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different X for different model versions (see the 4 version above)\n",
    "\n",
    "# 1) Version 1 (all lexical features)\n",
    "X_1 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "             'WC', 'WPS','i','emo_neg', 'emo_pos', 'Brunet', 'we', \n",
    "             'focuspast','TTR']]    \n",
    "\n",
    "\n",
    "# 2-3) Appraoches 2-3 (all lexical features + TF-IDF)\n",
    "X_23 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "             'Text', 'WC', 'WPS','i','emo_neg', 'emo_pos', 'Brunet', 'we',\n",
    "             'focuspast','TTR']]    \n",
    "\n",
    "# 4) Significant features only - differs between the languages based on LME results\n",
    "# Please uncomment the section to run it for your project\n",
    "\n",
    "# a) English\n",
    "# X_4 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "#              'Text', 'WC', 'WPS','emo_neg', 'emo_pos', 'Brunet', 'we', 'allnone',\n",
    "#              'emo_anx','emo_anger','emo_sad','TTR']]  \n",
    "\n",
    "# b) Dutch\n",
    "# X_4 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "             'Text', 'WPS', 'emo_pos']]\n",
    "\n",
    "# c) Spanish\n",
    "# X_4 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID','Text', ]]\n",
    "\n",
    "\n",
    "y = data_cleaned['PHQ8']\n",
    "groups = data_cleaned['participant_ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f6d735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the outer cross-validation strategy (GroupKFold)\n",
    "inner_cv = GroupKFold(n_splits=5)\n",
    "outer_cv = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87180062",
   "metadata": {},
   "source": [
    "#### 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7cac0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Average Inner RMSE: 6.19\n",
      "Average Inner RÂ²: 0.12\n",
      "Average Outer RMSE: 6.53\n",
      "Average Outer RÂ²: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_1,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "# Outer Loop\n",
    "nested_results = cross_validate(Inner_Grid, X_1, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups}, # pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)   # optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner RÂ²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer RÂ²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554421a",
   "metadata": {},
   "source": [
    "#### 2. Baseline + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ac928d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Average Inner RMSE: 6.19\n",
      "Average Inner RÂ²: 0.12\n",
      "Average Outer RMSE: 6.53\n",
      "Average Outer RÂ²: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_2,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "# Outer Loop\n",
    "nested_results = cross_validate(Inner_Grid, X_23, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups}, # pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)   # optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner RÂ²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer RÂ²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1527a3",
   "metadata": {},
   "source": [
    "#### 3. Automated + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59186c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Average Inner RMSE: 6.05\n",
      "Average Inner RÂ²: 0.16\n",
      "Average Outer RMSE: 6.49\n",
      "Average Outer RÂ²: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "\n",
    "Inner_Grid = GridSearchCV(pipeline_3,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "nested_results = cross_validate(Inner_Grid, X_23, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups},  # pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)    # optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner RÂ²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer RÂ²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53853dd6",
   "metadata": {},
   "source": [
    "#### 4. Stats-based + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ceddfb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Average Inner RMSE: 5.85\n",
      "Average Inner RÂ²: 0.21\n",
      "Average Outer RMSE: 6.51\n",
      "Average Outer RÂ²: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_4,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "nested_results = cross_validate(Inner_Grid, X_4, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups},  # pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)    # optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner RÂ²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer RÂ²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
