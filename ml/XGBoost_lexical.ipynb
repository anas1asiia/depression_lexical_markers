{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9c500f",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost_lexical.ipynb\n",
    "\n",
    "This script helps examine predictive power of lexical features (and TF-IDF) for \n",
    "predicting depression symptom severity (PHQ-8 scores). Developed as part of \n",
    "a study on multilingual lexical markers and depression severity.\n",
    "\n",
    "- Loads and preprocesses multilingual linguistic data (e.g., English, Dutch, Spanish)\n",
    "- Applies feature scaling and text vectorization (TF-IDF)\n",
    "- Constructs XGBoost regression pipelines with and without feature selection\n",
    "- Implements nested GroupKFold cross-validation\n",
    "- Supports multiple feature combinations (lexical features only, features + TF-IDF, etc.)\n",
    "- Evaluates performance using RMSE and R²\n",
    "- Supports grid search for hyperparameter tuning\n",
    "\n",
    "**Usage**:\n",
    "- Place your input CSV file in the desired directory.\n",
    "- Make sure the file includes a column named 'Text' containing the sentences.\n",
    "\n",
    "**Author**: Anastasiia Tokareva\n",
    "\n",
    "\n",
    "\n",
    "### Models tested:\n",
    "1. Baseline: full features, no TF-IDF\n",
    "2. Full features + TF-IDF\n",
    "3. Automatic Feature Selection: SelectKBest() + TSVD + TF-IDF\n",
    "4. Stats-based features + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a6f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ML pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GroupKFold, cross_validate, GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD   # TSVD\n",
    "\n",
    "# regressor\n",
    "# !pip install xgboost\n",
    "from xgboost import XGBRegressor  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f367bf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>participant_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education_Years</th>\n",
       "      <th>Height</th>\n",
       "      <th>Recording_Date</th>\n",
       "      <th>Task</th>\n",
       "      <th>PHQ8</th>\n",
       "      <th>ColumnID</th>\n",
       "      <th>...</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>TTR</th>\n",
       "      <th>COVID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RADAR-MDD-KCL-s1</td>\n",
       "      <td>71a74929-ce52-494f-9d41-d08cbcf53707</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>Unscripted</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>...</td>\n",
       "      <td>20.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RADAR-MDD-KCL-s1</td>\n",
       "      <td>71a74929-ce52-494f-9d41-d08cbcf53707</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>Unscripted</td>\n",
       "      <td>2</td>\n",
       "      <td>Text</td>\n",
       "      <td>...</td>\n",
       "      <td>29.91</td>\n",
       "      <td>7.25</td>\n",
       "      <td>16.62</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.534884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RADAR-MDD-KCL-s1</td>\n",
       "      <td>71a74929-ce52-494f-9d41-d08cbcf53707</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>Unscripted</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>...</td>\n",
       "      <td>27.75</td>\n",
       "      <td>8.61</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.565543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RADAR-MDD-KCL-s1</td>\n",
       "      <td>71a74929-ce52-494f-9d41-d08cbcf53707</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>Unscripted</td>\n",
       "      <td>0</td>\n",
       "      <td>Text</td>\n",
       "      <td>...</td>\n",
       "      <td>23.77</td>\n",
       "      <td>7.62</td>\n",
       "      <td>13.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.289855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RADAR-MDD-KCL-s1</td>\n",
       "      <td>71a74929-ce52-494f-9d41-d08cbcf53707</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>Unscripted</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>...</td>\n",
       "      <td>18.07</td>\n",
       "      <td>7.23</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.979592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Site                        participant_ID  Age  Gender  \\\n",
       "0  RADAR-MDD-KCL-s1  71a74929-ce52-494f-9d41-d08cbcf53707   56       1   \n",
       "1  RADAR-MDD-KCL-s1  71a74929-ce52-494f-9d41-d08cbcf53707   56       1   \n",
       "2  RADAR-MDD-KCL-s1  71a74929-ce52-494f-9d41-d08cbcf53707   56       1   \n",
       "3  RADAR-MDD-KCL-s1  71a74929-ce52-494f-9d41-d08cbcf53707   56       1   \n",
       "4  RADAR-MDD-KCL-s1  71a74929-ce52-494f-9d41-d08cbcf53707   56       1   \n",
       "\n",
       "   Education_Years  Height Recording_Date        Task  PHQ8 ColumnID  ...  \\\n",
       "0               14     165     2020-05-27  Unscripted     1     Text  ...   \n",
       "1               14     165     2020-08-01  Unscripted     2     Text  ...   \n",
       "2               14     165     2020-02-19  Unscripted     1     Text  ...   \n",
       "3               14     165     2019-11-28  Unscripted     0     Text  ...   \n",
       "4               14     165     2019-11-12  Unscripted     1     Text  ...   \n",
       "\n",
       "  AllPunc  Period  Comma  QMark  Exclam  Apostro  OtherP  Emoji        TTR  \\\n",
       "0   20.00   12.00   8.00    0.0     0.0     0.00     0.0    0.0  73.333333   \n",
       "1   29.91    7.25  16.62    0.3     0.0     5.74     0.0    0.0  39.534884   \n",
       "2   27.75    8.61  16.75    0.0     0.0     2.39     0.0    0.0  47.565543   \n",
       "3   23.77    7.62  13.90    0.0     0.0     2.24     0.0    0.0  45.289855   \n",
       "4   18.07    7.23   5.42    0.0     0.0     5.42     0.0    0.0  48.979592   \n",
       "\n",
       "   COVID  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ## 1. Clean your data\n",
    "data = pd.read_csv(\"C:/Users/your/file/name/here.csv\")  \n",
    "# remove missing values ('NA')\n",
    "data_cleaned = data.dropna(axis=0) \n",
    "\n",
    "# Below are the changes that were made to rename LIWC-generated column names, which differed \n",
    "# between the languages. Absolutist word frequency could only be extracted for English, so this\n",
    "# lexical feature was not included in the main ML models to enable comparison with Spanish\n",
    "# and Dutch data. Please uncomment the lines that you would like to run for your project.\n",
    "\n",
    "# a) English - remove the column with absolutist words \n",
    "# data_cleaned = data_cleaned.drop('allnone', axis=1)\n",
    "\n",
    "# b) Dutch - rename some columns to match English LIWC column names\n",
    "# data_cleaned = data_cleaned.rename(columns = {'posemo':'emo_pos', 'negemo':'emo_neg'})\n",
    "\n",
    "# c) Spanish - rename some columns to match English LIWC column names\n",
    "# data_cleaned = data_cleaned.rename(columns = {'EmoPos':'emo_pos', 'EmoNeg':'emo_neg', 'Yo':'i', 'Nosotro':'we', 'Pasado': 'focuspast'})\n",
    "\n",
    "\n",
    "## 2. Binarise COVID data\n",
    "data_cleaned['Recording_Date'] = pd.to_datetime(data_cleaned['Recording_Date'])\n",
    "\n",
    "# define COVID lockdown start and end dates (dates based on Leightley et al. (2021), https://pubmed.ncbi.nlm.nih.gov/34488697/)\n",
    "covid_start = pd.to_datetime('2020-03-23')\n",
    "covid_end = pd.to_datetime('2021-05-11')\n",
    "\n",
    "data_cleaned['COVID'] = ((data_cleaned['Recording_Date'] >= covid_start) & (data_cleaned['Recording_Date'] <= covid_end)).astype(int)\n",
    "data_cleaned.head(n=5)\n",
    "\n",
    "# COVID now added as the last column (0/1)\n",
    "data_cleaned.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7ed22",
   "metadata": {},
   "source": [
    "#### 1. Baseline: lexical features only \n",
    "E.g., frequency of past-tense verbs, WPS, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced5ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (StandardScaler for numerical, and FunctionTransformer for raw features)\n",
    "preprocessor_1 = ColumnTransformer([\n",
    "    ('num_scaler', StandardScaler(), ['Age', 'Education_Years', 'allnone',\n",
    "                                       'WC', 'WPS', 'i', 'emo_neg', 'emo_pos', 'Brunet', 'we',\n",
    "                                       'emo_anx', 'emo_anger', 'emo_sad', 'focuspast', 'TTR']),  # scale numerical features\n",
    "    ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])           # dummy variables unscaled\n",
    "])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_1 = Pipeline([\n",
    "    ('preprocessing', preprocessor_1),\n",
    "    ('regressor',  XGBRegressor(random_state = 42))  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19696e1c",
   "metadata": {},
   "source": [
    "#### Grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fddbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'regressor__max_depth': [3, 5, 7, 9],\n",
    "    'regressor__learning_rate': [0.1, 0.01, 0.001],\n",
    "    'regressor__subsample': [0.5, 0.7, 0.9],        # lowering the value prevents overfitting\n",
    "    'regressor__alpha': [0, 0.01, 0.1, 0.5, 1],     # L1 regularisation (default = 0)\n",
    "    'regressor__lambda': [0, 0.01, 0.1, 0.5, 1]      # L2 regularisation (default = 1)                      \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90880ec",
   "metadata": {},
   "source": [
    "#### 2. Baseline + TF-IDF\n",
    "Lexical features + TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed18fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (TF-IDF for text, StandardScaler for numerical)\n",
    "preprocessor_2 = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                                         # TF-IDF (no scaling)\n",
    "    ('num_scaler', StandardScaler(), ['Age', 'Education_Years', 'allnone',\n",
    "                                       'WC', 'WPS', 'i', 'emo_neg', 'emo_pos', 'Brunet', 'we',\n",
    "                                       'emo_anx', 'emo_anger', 'emo_sad', 'focuspast', 'TTR']),   # scale numerical features\n",
    "    ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])            # keeps dummy variables unscaled\n",
    "])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_2 = Pipeline([\n",
    "    ('preprocessing', preprocessor_2),\n",
    "    ('regressor', XGBRegressor(random_state = 42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3572ff",
   "metadata": {},
   "source": [
    "#### 3. Automated + TF-IDF \n",
    "Selection of features based on their F-score using SelectKBest + dimensionality reduction using TSVD to preserve top 100 componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80e8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (StandardScaler for numerical, and FunctionTransformer for raw features)\n",
    "preprocessor_3 = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=500), 'Text'),  # TF-IDF (no scaling)\n",
    "    ('num_scaler', StandardScaler(), ['Age', 'Education_Years', 'allnone',\n",
    "                                       'WC', 'WPS', 'i', 'emo_neg', 'emo_pos', 'Brunet', 'we',\n",
    "                                       'emo_anx', 'emo_anger', 'emo_sad', 'focuspast', 'TTR']),   # scale numerical features\n",
    "    ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])            # keeps dummy variables unscaled\n",
    "])\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_3 = Pipeline([\n",
    "    ('preprocessing', preprocessor_3),\n",
    "    ('feature_selection', SelectKBest(f_regression, k=100)),  \n",
    "    ('pca', TruncatedSVD(n_components=100)),  \n",
    "    ('regressor', XGBRegressor(random_state = 42)) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca291c",
   "metadata": {},
   "source": [
    "#### 4. Stats-based (no i, no past) + TF-IDF\n",
    "Removal of lexical features that were not strongly associated with PHQ-8 scores in Linear Mixed Modelling (LME), see lme in this repo for more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6386bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer (StandardScaler for numerical, and FunctionTransformer for raw features)\n",
    "\n",
    "## In our project, different associations between lexical features and depression severity (PHQ-8 scores) were observed \n",
    "# for different languages. Please uncomment the following section to run the required model.\n",
    "\n",
    "# a) English --> only frequency of past-tense verbs and first-person singular pronouns NOT associated with\n",
    "# PHQ-8 scores --> remove this features\n",
    "\n",
    "# preprocessor_4 = ColumnTransformer([\n",
    "#     ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "#     ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "#                                        'WC', 'WPS', 'emo_neg', 'emo_pos', 'Brunet', 'we', 'allnone',\n",
    "#                                        'emo_anx', 'emo_anger', 'emo_sad','TTR']),       # scale numerical features\n",
    "#     ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # keeps dummy variables unscaled\n",
    "# ])\n",
    "\n",
    "# b) Dutch --> only WPS and emo_pos were strongly associated with PHQ-8 scores --> remove the rest\n",
    "\n",
    "# preprocessor_4 = ColumnTransformer([\n",
    "#     ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "#     ('num_scaler', StandardScaler(), ['Age', 'Education_Years',\n",
    "#                                     'WPS', 'emo_pos']),                                 # scale numerical features\n",
    "#     ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])  # keeps dummy variables unscaled\n",
    "# ])\n",
    "\n",
    "# c) Spanish - no lexical features were strongly associated with PHQ-8 scores --> remove all\n",
    "\n",
    "# preprocessor_4 = ColumnTransformer([\n",
    "#     ('tfidf', TfidfVectorizer(max_features=500), 'Text'),                # TF-IDF (no scaling, as vectors are already scaled)\n",
    "#     ('num_scaler', StandardScaler(), ['Age', 'Education_Years']),                         # scale numerical features\n",
    "#     ('num_raw', FunctionTransformer(lambda x: x, validate=False), ['Gender', 'COVID'])   # keeps dummy variables unscaled\n",
    "# ])\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_4 = Pipeline([\n",
    "    ('preprocessing', preprocessor_4),\n",
    "    ('regressor', XGBRegressor(random_state = 42)) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f76bf7",
   "metadata": {},
   "source": [
    "### Custom RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f36ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RMSE scorer\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Define the scorers dictionary\n",
    "scorers = {\n",
    "    'rmse': make_scorer(rmse),\n",
    "    'r2': make_scorer(r2_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a5d1f",
   "metadata": {},
   "source": [
    "### Set up nested CFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cdc8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different X for different model versions (see the 4 versions above)\n",
    "\n",
    "# 1) Version 1 (all lexical features)\n",
    "X_1 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "             'WC', 'WPS','i','emo_neg', 'emo_pos', 'Brunet', 'we', \n",
    "             'focuspast','TTR']]    \n",
    "\n",
    "\n",
    "# 2-3) Appraoches 2-3 (all lexical features + TF-IDF)\n",
    "X_23 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "             'Text', 'WC', 'WPS','i','emo_neg', 'emo_pos', 'Brunet', 'we',\n",
    "             'focuspast','TTR']]    \n",
    "\n",
    "# 4) Significant features only - differs between the languages based on LME results\n",
    "# Please uncomment the section to run it for your project\n",
    "\n",
    "# a) English\n",
    "# X_4 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "#              'Text', 'WC', 'WPS','emo_neg', 'emo_pos', 'Brunet', 'we', 'allnone',\n",
    "#              'emo_anx','emo_anger','emo_sad','TTR']]  \n",
    "\n",
    "# b) Dutch\n",
    "# X_4 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID',\n",
    "#             'Text', 'WPS', 'emo_pos']]\n",
    "\n",
    "# c) Spanish\n",
    "# X_4 = data_cleaned[['Age', 'Education_Years', 'Gender', 'COVID','Text', ]]\n",
    "\n",
    "\n",
    "# y = data_cleaned[['PHQ8']]\n",
    "y = data_cleaned['PHQ8'].values.ravel()  # This will convert y to a 1D arra\n",
    "groups = data_cleaned['participant_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56c1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the outer cross-validation strategy (GroupKFold)\n",
    "inner_cv = GroupKFold(n_splits=5)\n",
    "outer_cv = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275102bb",
   "metadata": {},
   "source": [
    "#### 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40c712aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Average Inner RMSE: 5.16\n",
      "Average Inner R²: 0.21\n",
      "Average Outer RMSE: 5.78\n",
      "Average Outer R²: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_1,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "# Outer Loop\n",
    "nested_results = cross_validate(Inner_Grid, X_1, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups},  # pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)    # optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner R²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer R²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885ec23",
   "metadata": {},
   "source": [
    "#### 2. Baseline + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fd4710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Average Inner RMSE: 5.16\n",
      "Average Inner R²: 0.21\n",
      "Average Outer RMSE: 5.75\n",
      "Average Outer R²: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_2,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "# Outer Loop\n",
    "nested_results = cross_validate(Inner_Grid, X_23, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups}, #Need to pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)  # Optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner R²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer R²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09894243",
   "metadata": {},
   "source": [
    "#### 3. Automated + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e03e4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Average Inner RMSE: 4.87\n",
      "Average Inner R²: 0.29\n",
      "Average Outer RMSE: 5.72\n",
      "Average Outer R²: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_3,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "nested_results = cross_validate(Inner_Grid, X_23, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups}, #Need to pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)  # Optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner R²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer R²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711941f",
   "metadata": {},
   "source": [
    "#### 4. Stats-based + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a84b4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "Average Inner RMSE: 5.16\n",
      "Average Inner R²: 0.21\n",
      "Average Outer RMSE: 5.75\n",
      "Average Outer R²: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Inner Loop\n",
    "Inner_Grid = GridSearchCV(pipeline_4,\n",
    "                          param_grid,\n",
    "                          verbose = 1,\n",
    "                          cv=inner_cv,\n",
    "                          refit='rmse',\n",
    "                          return_train_score=True  \n",
    "                         )\n",
    "\n",
    "nested_results = cross_validate(Inner_Grid, X_4, y, \n",
    "                                cv=outer_cv,\n",
    "                                groups=groups,\n",
    "                                params={'groups': groups}, #Need to pass group information to inner split \n",
    "                                scoring=scorers,\n",
    "                                return_train_score=True)  # Optionally return train scores\n",
    "\n",
    "print(f\"Average Inner RMSE: {np.mean(nested_results['train_rmse']):.2f}\")\n",
    "print(f\"Average Inner R²: {np.mean(nested_results['train_r2']):.2f}\")\n",
    "print(f\"Average Outer RMSE: {np.mean(nested_results['test_rmse']):.2f}\")\n",
    "print(f\"Average Outer R²: {np.mean(nested_results['test_r2']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4f0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5707e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
